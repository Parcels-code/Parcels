{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ“ Working with Parcels output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial covers the format of the trajectory output exported by Parcels. **Parcels does not include advanced analysis or plotting functionality**, which users are suggested to write themselves to suit their research goals. Here we provide some starting points to explore the parcels output files yourself.\n",
    "\n",
    "- [**Reading the output file**](#reading-the-output-file)\n",
    "- [**Trajectory data structure**](#trajectory-data-structure)\n",
    "- [**Analysis**](#analysis)\n",
    "- [**Plotting**](#plotting)\n",
    "- [**Animations**](#animations)\n",
    "\n",
    "For more advanced reading and tutorials on the analysis of Lagrangian trajectories, we recommend checking out the [Lagrangian Diagnostics Analysis Cookbook](https://lagrangian-diags.readthedocs.io/en/latest/tutorials.html) and the project in general. The [TrajAn package](https://opendrift.github.io/trajan/index.html) can be used to read and plot datasets of Lagrangian trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import parcels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to create some parcels output to analyze. We simulate a set of particles using the setup described in the [Delay start tutorial](https://docs.oceanparcels.org/en/latest/examples/tutorial_delaystart.html). We will also add some user defined metadata to the output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CopernicusMarine data in the Agulhas region from the example_datasets\n",
    "example_dataset_folder = parcels.download_example_dataset(\n",
    "    \"CopernicusMarine_data_for_Argo_tutorial\"\n",
    ")\n",
    "\n",
    "ds_fields = xr.open_mfdataset(f\"{example_dataset_folder}/*.nc\", combine=\"by_coords\")\n",
    "ds_fields.load()  # load the dataset into memory\n",
    "\n",
    "# Convert to SGRID-compliant dataset and create FieldSet\n",
    "fields = {\"U\": ds_fields[\"uo\"], \"V\": ds_fields[\"vo\"]}\n",
    "ds_fset = parcels.convert.copernicusmarine_to_sgrid(fields=fields)\n",
    "fieldset = parcels.FieldSet.from_sgrid_conventions(ds_fset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Particle locations and initial time\n",
    "npart = 10  # number of particles to be released\n",
    "lon = 32 * np.ones(npart)\n",
    "lat = np.linspace(-32.5, -30.5, npart, dtype=np.float32)\n",
    "time = ds_fields.time.values[0] + np.arange(0, npart) * np.timedelta64(2, \"h\")\n",
    "z = np.repeat(ds_fields.depth.values[0], npart)\n",
    "\n",
    "pset = parcels.ParticleSet(\n",
    "    fieldset=fieldset, pclass=parcels.Particle, lon=lon, lat=lat, time=time, z=z\n",
    ")\n",
    "\n",
    "output_file = parcels.ParticleFile(\"output.zarr\", outputdt=np.timedelta64(2, \"h\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parcels saves some metadata in the output file with every simulation (Parcels version, CF convention information, etc.). This metadata is just a dictionary which is propogated to `xr.Dataset(attrs=...)` and is stored in the `.metadata` attribute. We are free to manipulate this dictionary to add any custom, xarray-compatible metadata relevant to their simulation. Here we add a custom metadata field `date_created` to the output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file.metadata[\"date_created\"] = datetime.now().isoformat()\n",
    "output_file.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To write the metadata to the output_file, we need to add it before running `pset.execute()` which writes the particleset including the metadata to the output_file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "pset.execute(\n",
    "    parcels.kernels.AdvectionRK4,\n",
    "    runtime=np.timedelta64(48, \"h\"),\n",
    "    dt=np.timedelta64(5, \"m\"),\n",
    "    output_file=output_file,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "TODO: add section on chunking\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the output file\n",
    "\n",
    "Parcels exports output trajectories in `zarr` [format](https://zarr.readthedocs.io/en/stable/). Files in `zarr` are typically _much_ smaller in size than netcdf, although may be slightly more challenging to handle (but `xarray` has a fairly seamless `open_zarr()` method). Note when we display the dataset we can see our custom metadata field `date_created`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_particles = xr.open_zarr(\"output.zarr\")\n",
    "\n",
    "print(ds_particles)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if you are running Parcels on multiple processors with `mpirun`, you will need to concatenate the files of each processor, see also the [MPI documentation](https://docs.oceanparcels.org/en/latest/examples/documentation_MPI.html#Reading-in-the-ParticleFile-data-in-zarr-format).\n",
    "\n",
    "Also, once you have loaded the data as an `xarray` DataSet using `xr.open_zarr()`, you can always save the file to NetCDF if you prefer with the `.to_netcdf()` method.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trajectory data structure\n",
    "\n",
    "The data zarr file are organised according to the [CF-convention for trajectories data](http://cfconventions.org/cf-conventions/v1.6.0/cf-conventions.html#_multidimensional_array_representation_of_trajectories) implemented with the [NCEI trajectory template](https://www.ncei.noaa.gov/data/oceans/ncei/formats/netcdf/v2.0/trajectoryIncomplete.cdl). The data is stored in a **two-dimensional array** with the dimensions `traj` and `obs`. Each particle trajectory is essentially stored as a time series where the coordinate data (`lon`, `lat`, `time`) are a function of the observation (`obs`).\n",
    "\n",
    "The output dataset used here contains **10 particles** and **13 observations**. Not every particle has 13 observations however; since we released particles at different times some particle trajectories are shorter than others.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=160)\n",
    "one_hour = np.timedelta64(1, \"h\")  # Define timedelta object to help with conversion\n",
    "time_from_start = ds_particles[\"time\"].values - fieldset.time_interval.left\n",
    "\n",
    "print(time_from_start / one_hour)  # timedelta / timedelta -> float number of hours"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the first observation occurs at a different time for each trajectory. So remember that `obs != time`\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Sometimes, trajectories are analyzed as they are stored: as individual time series. If we want to study the distance travelled as a function of time, the time we are interested in is the time relative to the start of the each particular trajectory: the array operations are simple since each trajectory is analyzed as a function of `obs`. The time variable is only needed to express the results in the correct units.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = ds_particles[\"lon\"].values\n",
    "y = ds_particles[\"lat\"].values\n",
    "distance = np.cumsum(\n",
    "    np.sqrt(np.square(np.diff(x)) + np.square(np.diff(y))), axis=1\n",
    ")  # d = (dx^2 + dy^2)^(1/2)\n",
    "\n",
    "real_time = time_from_start / one_hour  # convert time to hours\n",
    "time_since_release = (\n",
    "    real_time.transpose() - real_time[:, 0]\n",
    ")  # substract the initial time from each timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4), constrained_layout=True)\n",
    "\n",
    "ax1.set_ylabel(\"Distance travelled [m]\")\n",
    "ax1.set_xlabel(\"observation\", weight=\"bold\")\n",
    "d_plot = ax1.plot(distance.transpose())\n",
    "\n",
    "ax2.set_ylabel(\"Distance travelled [m]\")\n",
    "ax2.set_xlabel(\"time since release [hours]\", weight=\"bold\")\n",
    "d_plot_t = ax2.plot(time_since_release[1:], distance.transpose())\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two figures above show the same graph. Time is not needed to create the first figure. The time variable minus the first value of each trajectory gives the x-axis the correct units in the second figure.\n",
    "\n",
    "We can also plot the distance travelled as a function of the absolute time easily, since the `time` variable matches up with the data for each individual trajectory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "ax = plt.axes()\n",
    "ax.set_ylabel(\"Distance travelled [m]\")\n",
    "ax.set_xlabel(\"time [hours]\", weight=\"bold\")\n",
    "d_plot_t = ax.plot(real_time.T[1:], distance.transpose())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional selection\n",
    "\n",
    "In other cases, the processing of the data itself however depends on the absolute time at which the observations are made, e.g. studying seasonal phenomena. In that case the array structure is not as simple: the data must be selected by their `time` value. Here we show how the mean location of the particles evolves through time. This also requires the trajectory data to be aligned in time. The data are selected using `xr.DataArray.where()` which compares the time variable to a specific time. This type of selecting data with a condition (`ds_particles['time']==time`) is a powerful tool to analyze trajectory data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using xarray\n",
    "mean_lon_x = []\n",
    "mean_lat_x = []\n",
    "\n",
    "timerange = np.arange(\n",
    "    np.nanmin(ds_particles[\"time\"].values),\n",
    "    np.nanmax(ds_particles[\"time\"].values) + np.timedelta64(timedelta(hours=2)),\n",
    "    timedelta(hours=2),\n",
    ")  # timerange in nanoseconds\n",
    "\n",
    "for time in timerange:\n",
    "    # if all trajectories share an observation at time\n",
    "    if np.all(np.any(ds_particles[\"time\"] == time, axis=1)):\n",
    "        # find the data that share the time\n",
    "        mean_lon_x += [\n",
    "            np.nanmean(ds_particles[\"lon\"].where(ds_particles[\"time\"] == time).values)\n",
    "        ]\n",
    "        mean_lat_x += [\n",
    "            np.nanmean(ds_particles[\"lat\"].where(ds_particles[\"time\"] == time).values)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "ax = plt.axes()\n",
    "ax.set_ylabel(\"Meridional distance [m]\")\n",
    "ax.set_xlabel(\"Zonal distance [m]\")\n",
    "ax.grid()\n",
    "ax.scatter(mean_lon_x, mean_lat_x, marker=\"^\", s=80)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "\n",
    "Parcels output consists of particle trajectories through time and space. An important way to explore patterns in this information is to draw the trajectories in space. The [**trajan**](https://opendrift.github.io/trajan/index.html) package can be used to quickly plot parcels results, but users are encouraged to create their own figures, for example by using the comprehensive [**matplotlib**](https://matplotlib.org/) library. Here we show a basic setup on how to process the parcels output into trajectory plots and animations.\n",
    "\n",
    "Some other packages to help you make beautiful figures are:\n",
    "\n",
    "- [**cartopy**](https://scitools.org.uk/cartopy/docs/latest/), a map-drawing tool especially compatible with matplotlib\n",
    "- [**trajan**](https://opendrift.github.io/trajan/index.html), a package to quickly plot trajectories\n",
    "- [**cmocean**](https://matplotlib.org/cmocean/), a set of ocean-relevant colormaps\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To draw the trajectory data in space usually it is informative to draw points at the observed coordinates to see the resolution of the output and draw a line through them to separate the different trajectories. The coordinates to draw are in `lon` and `lat` and can be passed to either `matplotlib.pyplot.plot` or `matplotlib.pyplot.scatter`. Note however, that the default way matplotlib plots 2D arrays is to plot a separate set for each column. In the parcels 2D output, the columns correspond to the `obs` dimension, so to separate the different trajectories we need to transpose the 2D array using `.T`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(\n",
    "    1, 4, figsize=(16, 3.5), constrained_layout=True\n",
    ")\n",
    "\n",
    "###-Points-###\n",
    "ax1.set_title(\"Points\")\n",
    "ax1.scatter(ds_particles[\"lon\"].T, ds_particles[\"lat\"].T)\n",
    "###-Lines-###\n",
    "ax2.set_title(\"Lines\")\n",
    "ax2.plot(ds_particles[\"lon\"].T, ds_particles[\"lat\"].T)\n",
    "###-Points + Lines-###\n",
    "ax3.set_title(\"Points + Lines\")\n",
    "ax3.plot(ds_particles[\"lon\"].T, ds_particles[\"lat\"].T, marker=\"o\")\n",
    "###-Not Transposed-###\n",
    "ax4.set_title(\"Not transposed\")\n",
    "ax4.plot(ds_particles[\"lon\"], ds_particles[\"lat\"], marker=\"o\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animations\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trajectory plots like the ones above can become very cluttered for large sets of particles. To better see patterns, it's a good idea to create an animation in time and space. To do this, matplotlib offers an [animation package](https://matplotlib.org/stable/api/animation_api.html). Here we show how to use the [**FuncAnimation**](https://matplotlib.org/3.3.2/api/_as_gen/matplotlib.animation.FuncAnimation.html#matplotlib.animation.FuncAnimation) class to animate parcels trajectory data, based on [this visualisation tutorial](https://github.com/Parcels-code/10year-anniversary-session5/blob/eaf7ac35f43c222280fa5577858be81dc346c06b/animations_tutorial.ipynb) from 10-years Parcels. \n",
    "\n",
    "To correctly reveal the patterns in time we must remember that the `obs` dimension does not necessarily correspond to the `time` variable ([see the section of Trajectory data structure above](#trajectory-data-structure)). In the animation of the particles, we usually want to draw the points at each consecutive moment in time, not necessarily at each moment since the start of the trajectory. To do this we must [select the correct data](#conditional-selection) in each rendering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib\n",
    "from matplotlib.animation import FuncAnimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for interactive display of animation\n",
    "plt.rcParams[\"animation.html\"] = \"jshtml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of timesteps to animate\n",
    "nframes = 25  # use less frames for testing purposes\n",
    "nreducedtrails = 1  # every 10th particle will have a trail (if 1, all particles have trails. Adjust for faster performance)\n",
    "\n",
    "\n",
    "# Set up the colors and associated trajectories:\n",
    "# get release times for each particle (first valide obs for each trajectory)\n",
    "release_times = ds_particles[\"time\"].min(dim=\"obs\", skipna=True).values\n",
    "\n",
    "# get unique release times and assign colors\n",
    "unique_release_times = np.unique(release_times[~np.isnat(release_times)])\n",
    "n_release_times = len(unique_release_times)\n",
    "print(f\"Number of unique release times: {n_release_times}\")\n",
    "\n",
    "# choose a continuous colormap\n",
    "colormap = matplotlib.colormaps[\"tab20b\"]\n",
    "\n",
    "# set up a unique color for each release time\n",
    "release_time_to_color = {}\n",
    "for i, release_time in enumerate(unique_release_times):\n",
    "    release_time_to_color[release_time] = colormap(i / max(n_release_times - 1, 1))\n",
    "\n",
    "\n",
    "# --> Store data for all timeframes (this is needed for faster performance)\n",
    "print(\"Pre-computing all particle positions...\")\n",
    "all_particles_data = []\n",
    "for i, target_time in enumerate(timerange):\n",
    "    time_id = np.where(ds_particles[\"time\"] == target_time)\n",
    "    lons = ds_particles[\"lon\"].values[time_id]\n",
    "    lats = ds_particles[\"lat\"].values[time_id]\n",
    "    particle_indices = time_id[0]\n",
    "    valid = ~np.isnan(lons) & ~np.isnan(lats)\n",
    "\n",
    "    all_particles_data.append(\n",
    "        {\n",
    "            \"lons\": lons[valid],\n",
    "            \"lats\": lats[valid],\n",
    "            \"particle_indices\": particle_indices[valid],\n",
    "            \"valid_count\": np.sum(valid),\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "# figure setup\n",
    "fig, ax = plt.subplots(figsize=(6, 5), subplot_kw={\"projection\": ccrs.PlateCarree()})\n",
    "ax.set_xlim(30, 33)\n",
    "ax.set_xticks(np.arange(30, 33.5, 0.5))\n",
    "ax.set_xlabel(\"Longitude (deg E)\")\n",
    "ax.set_ylim(-33, -30)\n",
    "ax.set_yticks(ticks=np.arange(-33, -29.5, 0.5))\n",
    "ax.set_yticklabels(np.arange(33, 29.5, -0.5).astype(str))\n",
    "ax.set_ylabel(\"Latitude (deg S)\")\n",
    "ax.coastlines(color=\"saddlebrown\")\n",
    "ax.add_feature(cfeature.LAND, alpha=0.5, facecolor=\"saddlebrown\")\n",
    "\n",
    "# --> Use pre-computed data for initial setup\n",
    "initial_data = all_particles_data[0]\n",
    "initial_colors = []\n",
    "for particle_idx in initial_data[\"particle_indices\"]:\n",
    "    rt = release_times[particle_idx]\n",
    "    if rt in release_time_to_color:\n",
    "        initial_colors.append(release_time_to_color[rt])\n",
    "    else:\n",
    "        initial_colors.append(\"blue\")\n",
    "\n",
    "# --> plot first timestep\n",
    "scatter = ax.scatter(initial_data[\"lons\"], initial_data[\"lats\"], s=10, c=initial_colors)\n",
    "\n",
    "# --> initialize trails\n",
    "trail_plot = []\n",
    "\n",
    "# Set initial title\n",
    "t_str = str(timerange[0])[:19]  # Format datetime nicely\n",
    "title = ax.set_title(f\"Particles at t = {t_str}\")\n",
    "\n",
    "\n",
    "# loop over for animation\n",
    "def animate(i):\n",
    "    print(f\"Animating frame {i + 1}/{len(timerange)} at time {timerange[i]}\")\n",
    "    t_str = str(timerange[i])[:19]\n",
    "    title.set_text(f\"Particles at t = {t_str}\")\n",
    "\n",
    "    # Find particles at current time\n",
    "    current_data = all_particles_data[i]\n",
    "\n",
    "    if current_data[\"valid_count\"] > 0:\n",
    "        current_colors = []\n",
    "        for particle_idx in current_data[\"particle_indices\"]:\n",
    "            rt = release_times[particle_idx]\n",
    "            current_colors.append(release_time_to_color[rt])\n",
    "\n",
    "        scatter.set_offsets(np.c_[current_data[\"lons\"], current_data[\"lats\"]])\n",
    "        scatter.set_color(current_colors)\n",
    "\n",
    "        # --> add trails\n",
    "\n",
    "        for trail in trail_plot:\n",
    "            trail.remove()\n",
    "        trail_plot.clear()\n",
    "\n",
    "        trail_length = min(10, i)  # trails will have max length of 10 time steps\n",
    "\n",
    "        if trail_length > 0:\n",
    "            sampled_particles = current_data[\"particle_indices\"][\n",
    "                ::nreducedtrails\n",
    "            ]  # use all or sample if you want faster computation\n",
    "\n",
    "            for particle_idx in sampled_particles:\n",
    "                trail_lons = []\n",
    "                trail_lats = []\n",
    "                for j in range(i - trail_length, i + 1):\n",
    "                    past_data = all_particles_data[j]\n",
    "                    if particle_idx in past_data[\"particle_indices\"]:\n",
    "                        idx = np.where(past_data[\"particle_indices\"] == particle_idx)[\n",
    "                            0\n",
    "                        ][0]\n",
    "                        trail_lons.append(past_data[\"lons\"][idx])\n",
    "                        trail_lats.append(past_data[\"lats\"][idx])\n",
    "                if len(trail_lons) > 1:\n",
    "                    rt = release_times[particle_idx]\n",
    "                    color = release_time_to_color[rt]\n",
    "                    (trail,) = ax.plot(\n",
    "                        trail_lons, trail_lats, color=color, linewidth=0.6, alpha=0.6\n",
    "                    )\n",
    "                    trail_plot.append(trail)\n",
    "\n",
    "    else:\n",
    "        scatter.set_offsets(np.empty((0, 2)))\n",
    "\n",
    "\n",
    "# Create animation\n",
    "anim = FuncAnimation(fig, animate, frames=nframes, interval=100)\n",
    "plt.close(fig)\n",
    "anim"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Metagegevens bewerken",
  "kernelspec": {
   "display_name": "docs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
