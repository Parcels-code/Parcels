{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# ðŸ–¥ï¸ Nested Grids\n",
    "\n",
    "In some applications, you may have access to fields on different grids that each cover only part of the region of interest. Then, you would like to combine them all together. You may also have a grid covering the entire region and another one only covering part of it, but with a higher resolution. The set of those grids form what we call nested grids.\n",
    "\n",
    "In Parcels v4, we can use the new `uxarray` integration to determine in which grid a particle is located. We will demonstrate how to set up a simulation with multiple nested grids, and how to handle particle transitions between these grids.\n",
    "\n",
    "\n",
    "This tutorial shows how to use these Nested Fields with a very idealised example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as mtri\n",
    "import numpy as np\n",
    "import uxarray as ux\n",
    "import xarray as xr\n",
    "from shapely.geometry import MultiPoint, Point, Polygon\n",
    "from triangle import triangulate\n",
    "\n",
    "import parcels\n",
    "from parcels._datasets.structured.generated import simple_UV_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Setting up the individual Grids and Fields\n",
    "\n",
    "First define a zonal and meridional velocity field defined on a high resolution mesh. Both the zonal and meridional velocity are uniform, with velocities of 1 m/s and 0 m/s respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdim = 10\n",
    "ydim = 10\n",
    "\n",
    "ds_in = [None] * 2\n",
    "grid_polygons = [None] * 2\n",
    "\n",
    "grid_polygons[0] = np.array([(0, 0), (10, 0), (10, 10), (0, 10)])\n",
    "ds_in[0] = simple_UV_dataset(dims=(1, 1, ydim, xdim), mesh=\"spherical\").isel(\n",
    "    time=0, depth=0\n",
    ")\n",
    "\n",
    "ds_in[0][\"lon\"][:] = np.linspace(\n",
    "    grid_polygons[0][:, 0].min(), grid_polygons[0][:, 0].max(), xdim\n",
    ")\n",
    "ds_in[0][\"lat\"][:] = np.linspace(\n",
    "    grid_polygons[0][:, 1].min(), grid_polygons[0][:, 1].max(), ydim\n",
    ")\n",
    "lon_g, lat_g = np.meshgrid(ds_in[0][\"lon\"], ds_in[0][\"lat\"])\n",
    "ds_in[0][\"U\"][:] = 1.0\n",
    "ds_in[0][\"V\"][:] = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "Now define another velocity field on a coarser resolution grid. The zonal velocity is the same as for the finer resolution grid, but the meridional velocity is now a cosine as a function of longitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdim = 40\n",
    "ydim = 20\n",
    "\n",
    "grid_polygons[1] = np.array([(-10, -20), (60, -20), (60, 40), (-10, 40)])\n",
    "ds_in[1] = simple_UV_dataset(dims=(1, 1, ydim, xdim), mesh=\"spherical\").isel(\n",
    "    time=0, depth=0\n",
    ")\n",
    "\n",
    "ds_in[1][\"lon\"][:] = np.linspace(\n",
    "    grid_polygons[1][:, 0].min(), grid_polygons[1][:, 0].max(), xdim\n",
    ")\n",
    "ds_in[1][\"lat\"][:] = np.linspace(\n",
    "    grid_polygons[1][:, 1].min(), grid_polygons[1][:, 1].max(), ydim\n",
    ")\n",
    "lon_g, lat_g = np.meshgrid(ds_in[1][\"lon\"], ds_in[1][\"lat\"])\n",
    "ds_in[1][\"U\"][:] = 1.0\n",
    "ds_in[1][\"V\"][:] = np.cos(lon_g / 5 * np.pi / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Plot the two velocity fields on top of each other, indicating the grid boundaries in red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grids = len(ds_in)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i in range(n_grids):\n",
    "    ds = ds_in[i]\n",
    "    ax.quiver(ds.lon, ds.lat, ds.U, ds.V)\n",
    "    poly = grid_polygons[i]\n",
    "    ax.plot(\n",
    "        np.append(poly[:, 0], poly[0, 0]),\n",
    "        np.append(poly[:, 1], poly[1, 1]),\n",
    "        \"-r\",\n",
    "        lw=2,\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Creating a Delaunay triangulation of the nested Grids\n",
    "\n",
    "Now comes the important part: we need to create a Delaunay triangulation of the  nested Grids, so that we can efficiently determine in which Grid a particle is located at any given time. We use the `triangle` package to perform the triangulation, and `shapely` to handle the geometric operations. \n",
    "\n",
    "Note that we need to keep the edges of the polygons in the triangulation, so we need a [constrained (PSLG) Delaunay triangulation](https://en.wikipedia.org/wiki/Constrained_Delaunay_triangulation).\n",
    "\n",
    "The result is a set of triangles covering the nested Grids, which we can use to determine in which Grid a particle is located at any given time. It is important that the list of polygons is ordered from smallest to largest Grid, so that triangles in overlapping areas are assigned to the correct Grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from shapely.geometry import Point, Polygon\n",
    "from triangle import triangulate\n",
    "\n",
    "\n",
    "def constrained_triangulate_keep_edges(polygons):\n",
    "    \"\"\"Constrained triangulation while keeping polygon edges.\n",
    "\n",
    "    Args:\n",
    "      polygons: list of (Ni,2) numpy arrays (polygon boundary points in order)\n",
    "\n",
    "    Returns:\n",
    "      pts (P,2) array of vertex coordinates,\n",
    "      tris (M,3) array of triangle vertex indices,\n",
    "      face_poly (M,) mapping each triangle to the polygon index or -1.\n",
    "    \"\"\"\n",
    "    # build vertices + segments for Triangle PSLG\n",
    "    verts = []\n",
    "    segments = []\n",
    "    offset = 0\n",
    "    for poly in polygons:\n",
    "        Ni = len(poly)\n",
    "        verts.extend(poly.tolist())\n",
    "        segments.extend([[offset + j, offset + ((j + 1) % Ni)] for j in range(Ni)])\n",
    "        offset += Ni\n",
    "    verts = np.asarray(verts, dtype=float)\n",
    "    segments = np.asarray(segments, dtype=int)\n",
    "\n",
    "    mode = \"p\"  # \"p\" = PSLG (constrained triangulation)\n",
    "    B = triangulate({\"vertices\": verts, \"segments\": segments}, mode)\n",
    "\n",
    "    pts = B[\"vertices\"]\n",
    "    tris = B[\"triangles\"].astype(int)\n",
    "\n",
    "    # assign triangles to polygons using centroid test\n",
    "    shapely_polys = [Polygon(p) for p in polygons]\n",
    "    centers = pts[tris].mean(axis=1)\n",
    "    face_poly = np.full(len(tris), -1, dtype=int)\n",
    "    for ti, c in enumerate(centers):\n",
    "        for ip in range(len(shapely_polys)):\n",
    "            if shapely_polys[ip].contains(Point(c)):\n",
    "                face_poly[ti] = ip\n",
    "                break\n",
    "\n",
    "    return pts, tris, face_poly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "We can then run the triangulation and plot the resulting triangles to verify that they correctly cover the nested Grids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "points, face_tris, face_poly = constrained_triangulate_keep_edges(grid_polygons)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for i in range(n_grids)[::-1]:\n",
    "    tris = face_tris[face_poly == i]\n",
    "    ax.triplot(points[:, 0], points[:, 1], tris, label=f\"Nest {i}\")\n",
    "ax.scatter(points[:, 0], points[:, 1], s=10, c=\"k\")\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.legend()\n",
    "\n",
    "# reverse legend labels\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[::-1], labels[::-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Then, we convert the triangulation into a Parcels FieldSet using `Parcels.UxGrid()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build an xarray dataset compatible with UGRID / uxarray\n",
    "n_node = points.shape[0]\n",
    "n_face = face_tris.shape[0]\n",
    "n_max_face_nodes = face_tris.shape[1]\n",
    "\n",
    "ds_tri = xr.Dataset(\n",
    "    {\n",
    "        \"node_lon\": ((\"n_node\",), points[:, 0]),\n",
    "        \"node_lat\": ((\"n_node\",), points[:, 1]),\n",
    "        \"face_node_connectivity\": ((\"n_face\", \"n_max_face_nodes\"), face_tris),\n",
    "        \"face_polygon\": (\n",
    "            (\n",
    "                \"time\",\n",
    "                \"nz\",\n",
    "                \"n_face\",\n",
    "            ),\n",
    "            face_poly[np.newaxis, np.newaxis, :],\n",
    "            {\n",
    "                \"long_name\": \"Nested grid ID\",\n",
    "                \"location\": \"face\",\n",
    "                \"mesh\": \"delaunay\",\n",
    "            },\n",
    "        ),\n",
    "    },\n",
    "    coords={\n",
    "        \"time\": np.array([np.timedelta64(0, \"ns\")]),\n",
    "        \"nz\": np.array([0]),\n",
    "        \"n_node\": np.arange(n_node),\n",
    "        \"n_face\": np.arange(n_face),\n",
    "    },\n",
    "    attrs={\"Conventions\": \"UGRID-1.0\"},\n",
    ")\n",
    "\n",
    "uxda = ux.UxDataArray(ds_tri[\"face_polygon\"], uxgrid=ux.Grid(ds_tri))\n",
    "\n",
    "NestID = parcels.Field(\n",
    "    \"NestID\",\n",
    "    uxda,\n",
    "    # TODO note that here we need to use mesh=\"flat\" otherwise the hashing doesn't work. See https://github.com/Parcels-code/Parcels/pull/2439#discussion_r2627664010\n",
    "    parcels.UxGrid(uxda.uxgrid, z=uxda[\"nz\"], mesh=\"flat\"),\n",
    "    interp_method=parcels.interpolators.UxPiecewiseConstantFace,\n",
    ")\n",
    "fieldset = parcels.FieldSet([NestID])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "We can confirm that the FieldSet has been created correctly by running a Parcels simulation where particles sample the `NestID` field, which indicates in which nest each particle is located at any given time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = np.meshgrid(\n",
    "    np.linspace(1, 9, 5),\n",
    "    np.linspace(1, 9, 5),\n",
    ")\n",
    "\n",
    "NestParticle = parcels.Particle.add_variable(parcels.Variable(\"nestID\", dtype=np.int32))\n",
    "pset = parcels.ParticleSet(\n",
    "    fieldset, pclass=NestParticle, lon=X.flatten(), lat=Y.flatten()\n",
    ")\n",
    "\n",
    "\n",
    "def SampleNestID(particles, fieldset):\n",
    "    particles.nestID = fieldset.NestID[particles]\n",
    "\n",
    "\n",
    "pset.execute(SampleNestID, runtime=np.timedelta64(1, \"s\"), dt=np.timedelta64(1, \"s\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Indeed, the visualisation below shows that particles correctly identify the nest they are in based on their location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "cmap = plt.get_cmap(\"viridis\", n_grids)\n",
    "\n",
    "triang = mtri.Triangulation(\n",
    "    uxda.uxgrid.node_lon.values,\n",
    "    uxda.uxgrid.node_lat.values,\n",
    "    triangles=uxda.uxgrid.face_node_connectivity.values,\n",
    ")\n",
    "\n",
    "plot_args = {\n",
    "    \"cmap\": cmap,\n",
    "    \"edgecolors\": \"k\",\n",
    "    \"linewidth\": 0.5,\n",
    "    \"vmin\": 0,\n",
    "    \"vmax\": 2.0,\n",
    "}\n",
    "ax.tripcolor(\n",
    "    triang, facecolors=np.squeeze(uxda[0, :].values), shading=\"flat\", **plot_args\n",
    ")\n",
    "ax.scatter(pset.lon, pset.lat, c=pset.nestID, **plot_args)\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.set_title(\"Nesting visualisation (triangulation and interpolated particle values)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Advecting particles with nest transitions\n",
    "\n",
    "We can now set up a particle advection simulation using the nested grids. We first combine all the Fields into a single FieldSet. \n",
    "\n",
    "We rename the individual Fields by appending the nest index to their names, so that we can easily identify which Field belongs to which nest. We also add the `NestID` Field to the FieldSet (note that Parcels v4 supports combining structured and unstructured Fields into one FieldSet, which is very convenient for this usecase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [NestID]\n",
    "for i, ds in enumerate(ds_in):\n",
    "    # TODO : use FieldSet.from_sgrid_convetion here once #2437 is merged\n",
    "    grid = parcels.XGrid.from_dataset(ds, mesh=\"flat\")\n",
    "    U = parcels.Field(\"U\", ds[\"U\"], grid, interp_method=parcels.interpolators.XLinear)\n",
    "    V = parcels.Field(\"V\", ds[\"V\"], grid, interp_method=parcels.interpolators.XLinear)\n",
    "    UV = parcels.VectorField(\"UV\", U, V)\n",
    "\n",
    "    fset = parcels.FieldSet([U, V, UV])\n",
    "\n",
    "    # Make sure to attach the correct unit converter (since field-names have been changed)\n",
    "    fset.U.units = parcels.GeographicPolar()\n",
    "    fset.V.units = parcels.Geographic()\n",
    "\n",
    "    #\n",
    "    for fld in fset.fields.values():\n",
    "        fld.name = f\"{fld.name}{i}\"\n",
    "        fields.append(fld)\n",
    "fieldset = parcels.FieldSet(fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "We then define a custom Advection kernel that advects particles using the appropriate velocity Field based on the `NestID` at the particle's location. Note that for simplicity, we use Eulerian advection here, but in a real-world application you would typically use a higher-order scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdvectEE_Nests(particles, fieldset):\n",
    "    particles.nestID = fieldset.NestID[particles]\n",
    "\n",
    "    # TODO because of KernelParticle bug (GH #2143), we need to copy lon/lat/time to local variables\n",
    "    time = particles.time\n",
    "    z = particles.z\n",
    "    lat = particles.lat\n",
    "    lon = particles.lon\n",
    "    u = np.zeros_like(particles.lon)\n",
    "    v = np.zeros_like(particles.lat)\n",
    "\n",
    "    unique_ids = np.unique(particles.nestID)\n",
    "    for nid in unique_ids:\n",
    "        mask = particles.nestID == nid\n",
    "        UVField = getattr(fieldset, f\"UV{nid}\")\n",
    "        (u[mask], v[mask]) = UVField[time[mask], z[mask], lat[mask], lon[mask]]\n",
    "\n",
    "    particles.dlon += u * particles.dt\n",
    "    particles.dlat += v * particles.dt\n",
    "\n",
    "    # TODO particle states have to be updated manually because UVField is not called with `particles` argument (becaise of GH #2143)\n",
    "    particles.state = np.where(\n",
    "        np.isnan(u) | np.isnan(v),\n",
    "        parcels.StatusCode.ErrorInterpolation,\n",
    "        particles.state,\n",
    "    )\n",
    "\n",
    "\n",
    "def DeleteErrorParticles(particles, fieldset):\n",
    "    any_error = particles.state >= 50  # This captures all Errors\n",
    "    particles[any_error].state = parcels.StatusCode.Delete\n",
    "\n",
    "\n",
    "lat = np.linspace(-15, 25, 10)\n",
    "lon = np.full(len(lat), -5)\n",
    "\n",
    "pset = parcels.ParticleSet(fieldset, pclass=NestParticle, lon=lon, lat=lat)\n",
    "ofile = parcels.ParticleFile(\"nest_particles.zarr\", outputdt=np.timedelta64(1, \"D\"))\n",
    "pset.execute(\n",
    "    [AdvectEE_Nests, DeleteErrorParticles],\n",
    "    runtime=np.timedelta64(40, \"D\"),\n",
    "    dt=np.timedelta64(1, \"D\"),\n",
    "    output_file=ofile,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 3))\n",
    "\n",
    "ds_out = xr.open_zarr(\"nest_particles.zarr\")\n",
    "\n",
    "plt.plot(ds_out.lon.T, ds_out.lat.T, \"k\", linewidth=0.5)\n",
    "sc = ax.scatter(ds_out.lon, ds_out.lat, c=ds_out.nestID, s=4, cmap=cmap, vmin=0, vmax=2)\n",
    "xl, yl = ax.get_xlim(), ax.get_ylim()\n",
    "\n",
    "for i in range(n_grids):\n",
    "    poly = grid_polygons[i]\n",
    "    ax.plot(\n",
    "        np.append(poly[:, 0], poly[0, 0]),\n",
    "        np.append(poly[:, 1], poly[1, 1]),\n",
    "        \"-r\",\n",
    "        lw=2,\n",
    "    )\n",
    "ax.set_xlim(xl)\n",
    "ax.set_ylim(yl)\n",
    "ax.set_aspect(\"equal\")\n",
    "\n",
    "cbar = plt.colorbar(sc, ticks=[0, 1, 2], ax=ax)\n",
    "cbar.set_label(\"Nest ID\")\n",
    "ax.set_title(\"Particle advection through nests\")\n",
    "plt.tight_layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "Indeed, we can see that the particles follow the cosine oscillation pattern in the coarser grid, and move purely zonally in the finer grid.\n",
    "\n",
    "Note that in the plot above the particles at higher latitudes move farther in longitude-space (at a constant zonal velocity) because of the curvature of the earth, so that is expected."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
